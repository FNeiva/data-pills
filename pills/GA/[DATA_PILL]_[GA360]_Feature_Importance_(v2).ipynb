{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[DATA PILL] [GA360] - Feature Importance (v2).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmVwSGJZdhwr"
      },
      "source": [
        "**PLEASE MAKE A COPY BEFORE CHANGING**\n",
        "\n",
        "**Copyright** 2021 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "\n",
        "\n",
        "<b>Important</b>\n",
        "This content are intended for educational and informational purposes only."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuoFxgMPfFvT"
      },
      "source": [
        "## Introduction \n",
        "<b>Purpose:</b> The goal of this colab is to show an example of how to calculate conversion probability. As a result we can create the feature importance report.\n",
        "\n",
        "**Key notes**\n",
        "\n",
        "*   This example assumes enhanced ecommerce is implemented (we are predicting transactions).\n",
        "*   It is possible to adjust the query to predict other events instead of a transaction.\n",
        "\n",
        "**Instructions**\n",
        "*   First of all: <b>MAKE A COPY</b>;\n",
        "*   Fulfill the query parameters in the Box 1;\n",
        "*   In the menu above click in Runtime > Run All;\n",
        "*   Authorize your credentials;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYYfkF-7vdTP"
      },
      "source": [
        "## User Input (Training Query)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wx8PfPYcLQqg",
        "cellView": "form"
      },
      "source": [
        "project_id = 'your-billing-project-id'#@param\n",
        "table = 'your-project-id.your-ga-dataset.ga_sessions_*'#@param\n",
        "lookback_start_date = '2018-08-01'#@param {type:\"date\"}\n",
        "lookback_end_date = '2018-08-31'#@param {type:\"date\"}\n",
        "conversion_window_start_date = '2018-09-01'#@param {type:\"date\"}\n",
        "conversion_window_end_date = '2018-09-30'#@param {type:\"date\"}\n",
        "prediction_type = 'transaction'#@param['transaction', 'event']\n",
        "event_filter_type = 'eventLabel'#@param['eventCategory', 'eventAction', 'eventLabel', ' ']\n",
        "event_filter_value = 'conversion'#@param\n",
        "test_size = 0.5#@param\n",
        "downsample_majority_class = 0.1#@param {type:\"slider\", min:0.1, max:1, step:0.1}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2WbVWBxfEpi"
      },
      "source": [
        "## User Input (Classification Query)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_SC9p2bfCkK",
        "cellView": "form"
      },
      "source": [
        "classification_start_date = '2019-10-01'#@param {type:\"date\"}\n",
        "classification_end_date = '2019-10-31'#@param {type:\"date\"}\n",
        "index_dimension = 'ga:dimension14'#@param\n",
        "value_dimension = 'ga:dimension15'#@param\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kre62wxNviEg"
      },
      "source": [
        "## Code Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HJ-BSp1bniG"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from google.colab import auth, files\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
        "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder, StandardScaler\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFDW-WVVas3j"
      },
      "source": [
        "# Function to print results\n",
        "def results(X_test, Y_test, clf):\n",
        "    probs = clf.predict_proba(X_test)\n",
        "    auc_ = roc_auc_score(Y_test, probs[:,1])\n",
        "    print(\"AUC: %.4f\" % auc_)\n",
        "    predictions = clf.predict(X_test)\n",
        "    print(\"accuracy: %.4f\" % accuracy_score(Y_test, predictions))\n",
        "    print(classification_report(Y_test, clf.predict(X_test)))\n",
        "\n",
        "# Function to plot a roc curve\n",
        "def plot_roc_curve(X_test, model):\n",
        "    probs = model.predict_proba(X_test)\n",
        "    preds = probs[:,1]\n",
        "    fpr, tpr, threshold = roc_curve(y_test, preds)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.title('AdaBoosting AUC Curve')\n",
        "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "    plt.legend(loc = 'lower right')\n",
        "    plt.plot([0, 1], [0, 1],'r--')\n",
        "    plt.xlim([0, 1])\n",
        "    plt.ylim([0, 1])\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.show()\n",
        "\n",
        "# Function to plot feature importance (valid for adaBoosting only)\n",
        "def feature_relevance(X_test, model):\n",
        "    names = X_test.columns\n",
        "    feature_importance = model.feature_importances_\n",
        "    # make importances relative to max importance\n",
        "    feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
        "    sorted_idx = np.argsort(feature_importance)\n",
        "    pos = np.arange(sorted_idx.shape[0]) + .5\n",
        "    plt.figure(figsize=(20,10))\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
        "    plt.yticks(pos,map(lambda x: names[x], sorted_idx))\n",
        "    plt.xlabel('Relative Importance')\n",
        "    plt.title('Variable Importance')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-B2SzEEcA0L"
      },
      "source": [
        "# Authenticate the user to access BigQuery Projects\n",
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4auG4L21vMMc"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsgDpGu-arO9"
      },
      "source": [
        "# Build the query\n",
        "dc ={}\n",
        "dc['project_id'] = project_id\n",
        "dc['table'] = table\n",
        "dc['lookback_start_date'] = lookback_start_date.replace('-', '')\n",
        "dc['lookback_end_date'] = lookback_end_date.replace('-', '')\n",
        "dc['conversion_window_start_date'] = conversion_window_start_date.replace('-', '')\n",
        "dc['conversion_window_end_date'] = conversion_window_end_date.replace('-', '')\n",
        "dc['prediction_type'] = prediction_type\n",
        "dc['event_filter_type'] = event_filter_type\n",
        "dc['event_filter_value'] = event_filter_value\n",
        "dc['downsample_majority_class'] = downsample_majority_class\n",
        "dc['classification_start_date'] = classification_start_date.replace('-', '')\n",
        "dc['classification_end_date'] = classification_end_date.replace('-', '')\n",
        "\n",
        "q1 = \"\"\"\n",
        "WITH\n",
        "  latest_session AS (\n",
        "  SELECT\n",
        "    * EXCEPT(rn)\n",
        "  FROM (\n",
        "    SELECT\n",
        "      ROW_NUMBER() OVER(PARTITION BY clientid ORDER BY visitnumber DESC) AS rn,\n",
        "      clientid,\n",
        "      visitNumber,\n",
        "      channelgrouping,\n",
        "      IF(device.browser NOT IN ('Chrome', 'Safari', 'Firefox', 'Android Webview', 'Edge'), 'Others', device.browser) as browser,\n",
        "      device.deviceCategory,\n",
        "      IF(device.operatingSystem NOT IN('Android', 'iOS', 'Windows', 'Macintosh', 'Linux'), 'Others', device.operatingSystem ) AS operatingSystem,\n",
        "      geoNetwork.region\n",
        "    FROM\n",
        "      `{table}`\n",
        "    WHERE\n",
        "      _TABLE_SUFFIX BETWEEN '{lookback_start_date}' AND '{lookback_end_date}'\n",
        "      AND clientid IS NOT NULL)\n",
        "  WHERE\n",
        "    rn = 1 ),\n",
        "\n",
        "session_hits as (\n",
        "SELECT\n",
        "    clientid,\n",
        "    SUM(totals.visits) AS visits,\n",
        "    SUM(totals.pageviews) AS pageviews,\n",
        "    SUM(totals.hits) AS hits,\n",
        "    SUM(totals.timeonsite) AS timeonsite,\n",
        "    SUM(totals.bounces) AS bounces,\n",
        "    SUM(CASE WHEN EXTRACT(HOUR FROM TIMESTAMP_SECONDS(visitStartTime) AT TIME ZONE \"America/Los_Angeles\") IN (5,6,7,8,9,10) THEN 1 ELSE 0 END) AS morning_visits,\n",
        "    SUM(CASE WHEN EXTRACT(HOUR FROM TIMESTAMP_SECONDS(visitStartTime) AT TIME ZONE \"America/Los_Angeles\") IN (11,12,13,14,15,16) THEN 1 ELSE 0 END) AS daytime_visits,\n",
        "    SUM(CASE WHEN EXTRACT(HOUR FROM TIMESTAMP_SECONDS(visitStartTime) AT TIME ZONE \"America/Los_Angeles\") IN (17,18,19,20,21,22) THEN 1 ELSE 0 END) AS evening_visits,\n",
        "    SUM(CASE WHEN EXTRACT(HOUR FROM TIMESTAMP_SECONDS(visitStartTime) AT TIME ZONE \"America/Los_Angeles\") IN (23,24,0,1,2,3,4) THEN 1 ELSE 0 END) AS midnight_visits,\n",
        "    SUM(totals.transactions) AS conversion,\n",
        "    SUM(totals.totalTransactionRevenue) / 100000 AS revenue\n",
        "FROM\n",
        "  `{table}`\n",
        "WHERE\n",
        "  _TABLE_SUFFIX BETWEEN '{lookback_start_date}' AND '{lookback_end_date}' AND clientid IS NOT NULL\n",
        "GROUP BY 1),\n",
        " \n",
        "converted as (\n",
        "SELECT \n",
        "  *\n",
        "FROM (\n",
        "  SELECT \n",
        "    clientid,\n",
        "    SUM(totals.transactions) AS y_conversions\n",
        "  FROM\n",
        "    `{table}`\n",
        "  WHERE\n",
        "    _TABLE_SUFFIX BETWEEN '{conversion_window_start_date}' AND '{conversion_window_end_date}' AND clientid IS NOT NULL\n",
        "  GROUP BY 1)\n",
        "WHERE \n",
        "  y_conversions > 0\n",
        "),\n",
        "\n",
        "joined as(\n",
        "SELECT\n",
        "  sh.clientid,\n",
        "  ls.channelgrouping AS last_channel,\n",
        "  ls.browser,\n",
        "  ls.deviceCategory,\n",
        "  ls.operatingSystem,\n",
        "  ls.region,\n",
        "  ls.visitnumber AS current_visit,\n",
        "  IFNULL(SUM(sh.visits), 0) AS total_visits,\n",
        "  IFNULL(SUM(sh.pageviews), 0) AS total_pageviews,\n",
        "  IFNULL(SUM(sh.hits), 0) AS total_hits,\n",
        "  IFNULL(SUM(sh.timeonsite), 0) AS total_timeonsite,\n",
        "  IFNULL(SUM(sh.bounces), 0) AS total_bounces,\n",
        "  IFNULL(SUM(sh.morning_visits), 0) AS total_morning_visits,\n",
        "  IFNULL(SUM(sh.daytime_visits), 0) AS total_daytime_visits,\n",
        "  IFNULL(SUM(sh.evening_visits), 0) AS total_evening_visits,\n",
        "  IFNULL(SUM(sh.midnight_visits), 0) AS total_midnight_visits,\n",
        "  IFNULL(SUM(sh.conversion), 0) AS total_conversions,\n",
        "  IF(IFNULL(SUM(c.y_conversions), 0) > 0, 1, 0) AS y_conversions\n",
        "FROM\n",
        "  session_hits sh LEFT OUTER JOIN latest_session ls\n",
        "  ON sh.clientid = ls.clientid\n",
        "  LEFT OUTER JOIN converted c ON sh.clientid = c.clientid\n",
        "GROUP BY 1,2,3,4,5,6,7)\n",
        "\n",
        "SELECT * FROM joined WHERE y_conversions = 0 AND RAND() <= {downsample_majority_class} UNION ALL(SELECT * FROM joined WHERE y_conversions = 1)\n",
        "\"\"\".format(**dc)\n",
        "\n",
        "q2 = \"\"\"\n",
        "\n",
        "WITH\n",
        "  latest_session AS (\n",
        "  SELECT\n",
        "    * EXCEPT(rn)\n",
        "  FROM (\n",
        "    SELECT\n",
        "      ROW_NUMBER() OVER(PARTITION BY clientid ORDER BY visitnumber DESC) AS rn,\n",
        "      clientid,\n",
        "      visitNumber,\n",
        "      channelgrouping,\n",
        "      IF(device.browser NOT IN ('Chrome', 'Safari', 'Firefox', 'Samsung Internet', 'Android Webview', 'Edge'), 'Others', device.browser) as browser,\n",
        "      device.deviceCategory,\n",
        "      IF(device.operatingSystem NOT IN('Android', 'iOS', 'Windows', 'Macintosh', 'Linux'), 'Others', device.operatingSystem ) AS operatingSystem,\n",
        "      geoNetwork.region\n",
        "    FROM\n",
        "      `{table}`\n",
        "    WHERE\n",
        "      _TABLE_SUFFIX BETWEEN '{lookback_start_date}' AND '{lookback_end_date}'\n",
        "      AND clientid IS NOT NULL)\n",
        "  WHERE\n",
        "    rn = 1 ),\n",
        "\n",
        "session_hits as (\n",
        "SELECT\n",
        "    clientid,\n",
        "    SUM(totals.visits) AS visits,\n",
        "    SUM(totals.pageviews) AS pageviews,\n",
        "    SUM(totals.hits) AS hits,\n",
        "    SUM(totals.timeonsite) AS timeonsite,\n",
        "    SUM(totals.bounces) AS bounces,\n",
        "    SUM(CASE WHEN EXTRACT(HOUR FROM TIMESTAMP_SECONDS(visitStartTime) AT TIME ZONE \"America/Los_Angeles\") IN (5,6,7,8,9,10) THEN 1 ELSE 0 END) AS morning_visits,\n",
        "    SUM(CASE WHEN EXTRACT(HOUR FROM TIMESTAMP_SECONDS(visitStartTime) AT TIME ZONE \"America/Los_Angeles\") IN (11,12,13,14,15,16) THEN 1 ELSE 0 END) AS daytime_visits,\n",
        "    SUM(CASE WHEN EXTRACT(HOUR FROM TIMESTAMP_SECONDS(visitStartTime) AT TIME ZONE \"America/Los_Angeles\") IN (17,18,19,20,21,22) THEN 1 ELSE 0 END) AS evening_visits,\n",
        "    SUM(CASE WHEN EXTRACT(HOUR FROM TIMESTAMP_SECONDS(visitStartTime) AT TIME ZONE \"America/Los_Angeles\") IN (23,24,0,1,2,3,4) THEN 1 ELSE 0 END) AS midnight_visits,\n",
        "    SUM(totals.transactions) AS conversion,\n",
        "    SUM(totals.totalTransactionRevenue) / 100000 AS revenue\n",
        "FROM\n",
        "  `{table}`\n",
        "WHERE\n",
        "  _TABLE_SUFFIX BETWEEN '{lookback_start_date}' AND '{lookback_end_date}' AND clientid IS NOT NULL\n",
        "GROUP BY 1),\n",
        " \n",
        "converted as (\n",
        "SELECT \n",
        "  *\n",
        "FROM (\n",
        "  SELECT \n",
        "    clientid,\n",
        "    COUNT(1) AS y_conversions\n",
        "  FROM\n",
        "    `{table}`, UNNEST(hits) h\n",
        "  WHERE\n",
        "    _TABLE_SUFFIX BETWEEN '{conversion_window_start_date}' AND '{conversion_window_end_date}' AND clientid IS NOT NULL\n",
        "    AND h.eventInfo.{event_filter_type}\t= '{event_filter_value}'\n",
        "  GROUP BY 1)\n",
        "WHERE \n",
        "  y_conversions > 0\n",
        "),\n",
        "\n",
        "joined as(\n",
        "SELECT\n",
        "  sh.clientid,\n",
        "  ls.channelgrouping AS last_channel,\n",
        "  ls.browser,\n",
        "  ls.deviceCategory,\n",
        "  ls.operatingSystem,\n",
        "  ls.region,\n",
        "  ls.visitnumber AS current_visit,\n",
        "  IFNULL(SUM(sh.visits), 0) AS total_visits,\n",
        "  IFNULL(SUM(sh.pageviews), 0) AS total_pageviews,\n",
        "  IFNULL(SUM(sh.hits), 0) AS total_hits,\n",
        "  IFNULL(SUM(sh.timeonsite), 0) AS total_timeonsite,\n",
        "  IFNULL(SUM(sh.bounces), 0) AS total_bounces,\n",
        "  IFNULL(SUM(sh.morning_visits), 0) AS total_morning_visits,\n",
        "  IFNULL(SUM(sh.daytime_visits), 0) AS total_daytime_visits,\n",
        "  IFNULL(SUM(sh.evening_visits), 0) AS total_evening_visits,\n",
        "  IFNULL(SUM(sh.midnight_visits), 0) AS total_midnight_visits,\n",
        "  IFNULL(SUM(sh.conversion), 0) AS total_conversions,\n",
        "  IF(IFNULL(SUM(c.y_conversions), 0) > 0, 1, 0) AS y_conversions\n",
        "FROM\n",
        "  session_hits sh LEFT OUTER JOIN latest_session ls\n",
        "  ON sh.clientid = ls.clientid\n",
        "  LEFT OUTER JOIN converted c ON sh.clientid = c.clientid\n",
        "GROUP BY 1,2,3,4,5,6,7)\n",
        "\n",
        "SELECT * FROM joined WHERE y_conversions = 0 AND RAND() <= {downsample_majority_class} UNION ALL(SELECT * FROM joined WHERE y_conversions = 1)\n",
        "\n",
        "\"\"\".format(**dc)\n",
        "\n",
        "\n",
        "q3 = \"\"\"\n",
        "WITH\n",
        "  latest_session AS (\n",
        "  SELECT\n",
        "    * EXCEPT(rn)\n",
        "  FROM (\n",
        "    SELECT\n",
        "      ROW_NUMBER() OVER(PARTITION BY clientid ORDER BY visitnumber DESC) AS rn,\n",
        "      clientid,\n",
        "      visitNumber,\n",
        "      channelgrouping,\n",
        "      IF(device.browser NOT IN ('Chrome', 'Safari', 'Firefox', 'Android Webview', 'Edge'), 'Others', device.browser) as browser,\n",
        "      device.deviceCategory,\n",
        "      IF(device.operatingSystem NOT IN('Android', 'iOS', 'Windows', 'Macintosh', 'Linux'), 'Others', device.operatingSystem ) AS operatingSystem,\n",
        "      geoNetwork.region\n",
        "    FROM\n",
        "      `{table}`\n",
        "    WHERE\n",
        "      _TABLE_SUFFIX BETWEEN '{classification_start_date}' AND '{classification_end_date}'\n",
        "      AND clientid IS NOT NULL)\n",
        "  WHERE\n",
        "    rn = 1 ),\n",
        "\n",
        "session_hits as (\n",
        "SELECT\n",
        "    clientid,\n",
        "    SUM(totals.visits) AS visits,\n",
        "    SUM(totals.pageviews) AS pageviews,\n",
        "    SUM(totals.hits) AS hits,\n",
        "    SUM(totals.timeonsite) AS timeonsite,\n",
        "    SUM(totals.bounces) AS bounces,\n",
        "    SUM(CASE WHEN EXTRACT(HOUR FROM TIMESTAMP_SECONDS(visitStartTime) AT TIME ZONE \"America/Los_Angeles\") IN (5,6,7,8,9,10) THEN 1 ELSE 0 END) AS morning_visits,\n",
        "    SUM(CASE WHEN EXTRACT(HOUR FROM TIMESTAMP_SECONDS(visitStartTime) AT TIME ZONE \"America/Los_Angeles\") IN (11,12,13,14,15,16) THEN 1 ELSE 0 END) AS daytime_visits,\n",
        "    SUM(CASE WHEN EXTRACT(HOUR FROM TIMESTAMP_SECONDS(visitStartTime) AT TIME ZONE \"America/Los_Angeles\") IN (17,18,19,20,21,22) THEN 1 ELSE 0 END) AS evening_visits,\n",
        "    SUM(CASE WHEN EXTRACT(HOUR FROM TIMESTAMP_SECONDS(visitStartTime) AT TIME ZONE \"America/Los_Angeles\") IN (23,24,0,1,2,3,4) THEN 1 ELSE 0 END) AS midnight_visits,\n",
        "    SUM(totals.transactions) AS conversion,\n",
        "    SUM(totals.totalTransactionRevenue) / 100000 AS revenue\n",
        "FROM\n",
        "  `{table}`\n",
        "WHERE\n",
        "  _TABLE_SUFFIX BETWEEN '{classification_start_date}' AND '{classification_end_date}' AND clientid IS NOT NULL\n",
        "GROUP BY 1),\n",
        " \n",
        "\n",
        "\n",
        "joined as(\n",
        "SELECT\n",
        "  sh.clientid,\n",
        "  ls.channelgrouping AS last_channel,\n",
        "  ls.browser,\n",
        "  ls.deviceCategory,\n",
        "  ls.operatingSystem,\n",
        "  ls.region,\n",
        "  ls.visitnumber AS current_visit,\n",
        "  IFNULL(SUM(sh.visits), 0) AS total_visits,\n",
        "  IFNULL(SUM(sh.pageviews), 0) AS total_pageviews,\n",
        "  IFNULL(SUM(sh.hits), 0) AS total_hits,\n",
        "  IFNULL(SUM(sh.timeonsite), 0) AS total_timeonsite,\n",
        "  IFNULL(SUM(sh.bounces), 0) AS total_bounces,\n",
        "  IFNULL(SUM(sh.morning_visits), 0) AS total_morning_visits,\n",
        "  IFNULL(SUM(sh.daytime_visits), 0) AS total_daytime_visits,\n",
        "  IFNULL(SUM(sh.evening_visits), 0) AS total_evening_visits,\n",
        "  IFNULL(SUM(sh.midnight_visits), 0) AS total_midnight_visits,\n",
        "  IFNULL(SUM(sh.conversion), 0) AS total_conversions\n",
        "FROM\n",
        "  session_hits sh LEFT OUTER JOIN latest_session ls\n",
        "  ON sh.clientid = ls.clientid\n",
        "GROUP BY 1,2,3,4,5,6,7)\n",
        "\n",
        "SELECT * FROM joined\n",
        "\n",
        "\n",
        "\"\"\".format(**dc)\n",
        "if prediction_type == 'transaction':\n",
        "    q = q1\n",
        "else:\n",
        "    q = q2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVubqAV6NqPp"
      },
      "source": [
        "%%time\n",
        "df = pd.io.gbq.read_gbq(q, project_id=project_id, verbose=False, dialect='standard')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2m-XciRYMO4-"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAeRsAGqSFmM"
      },
      "source": [
        "print(\"Dataset has {} rows and {} columns\".format(df.shape[0], df.shape[1]))\n",
        "print()\n",
        "print(\"Class distribution:\")\n",
        "print(df.y_conversions.value_counts())\n",
        "print()\n",
        "print(\"converters to non converters proportion:\")\n",
        "print(df.y_conversions.value_counts()[1] / df.y_conversions.value_counts()[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGPTJpKLnC-d"
      },
      "source": [
        "# Drop the label and clientid (Xs)\n",
        "X_all = df.drop(['y_conversions', 'clientid', 'region', 'browser', 'operatingSystem'],1)\n",
        "# Select the label to predict (Ys)\n",
        "y_all = df['y_conversions']\n",
        "# Get all categorical columns in a list.\n",
        "text = list(X_all.select_dtypes(include=['object', 'category']).columns)\n",
        "# Get all numeric columns in a list.\n",
        "numbers = list(X_all.select_dtypes(include=np.number))\n",
        "# Convert categoricals into the proper type\n",
        "X_all.loc[:,text] = X_all.loc[:,text].astype('category'\u001c)\n",
        "# Stratified split into train, test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, \n",
        "                                                    test_size = test_size,\n",
        "                                                    random_state = 4,\n",
        "                                                    stratify = y_all)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzOLghgQDsQb"
      },
      "source": [
        "# Build and fit the pipeline\n",
        "\n",
        "preprocess = make_column_transformer(\n",
        "    (OneHotEncoder(handle_unknown='ignore'), text),\n",
        "    (StandardScaler(), numbers))\n",
        "\n",
        "pipe_ada = make_pipeline(\n",
        "    preprocess,\n",
        "    AdaBoostClassifier(n_estimators=150, learning_rate=0.1, random_state=42)\n",
        ")\n",
        "\n",
        "pipe_reg = make_pipeline(\n",
        "    preprocess,\n",
        "    LogisticRegressionCV(max_iter=1000)\n",
        ")\n",
        "\n",
        "pipe_ada.fit(X_train,y_train)\n",
        "pipe_reg.fit(X_train, y_train)\n",
        "\n",
        ";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7gaiZIen2e1"
      },
      "source": [
        "# Plot the model results\n",
        "print('Adaboosting Results:')\n",
        "print()\n",
        "results(X_test, y_test, pipe_ada)\n",
        "plot_roc_curve(X_test, pipe_ada)\n",
        "\n",
        "print()\n",
        "print('Logistic Regression Results:')\n",
        "print()\n",
        "results(X_test, y_test, pipe_reg)\n",
        "plot_roc_curve(X_test, pipe_reg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k09QFncT8WW1"
      },
      "source": [
        "cat = list(pipe_ada.named_steps.columntransformer.transformers_[0][1].get_feature_names())\n",
        "features = cat + numbers\n",
        "X_test = pipe_ada.named_steps.columntransformer.transform(X_test)\n",
        "X_test = pd.DataFrame(X_test, columns = features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvoYzq2IGNwl"
      },
      "source": [
        "feature_relevance(X_test, pipe_ada.named_steps.adaboostclassifier)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J29fUCshVlvn"
      },
      "source": [
        "%%time\n",
        "df = pd.io.gbq.read_gbq(q3, project_id=project_id, verbose=False, dialect='standard')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yarEJhybV8cx"
      },
      "source": [
        "preds = pipe_reg.predict_proba(df.drop(['clientid', 'region', 'browser', 'operatingSystem'],1))\n",
        "df['prob'] = preds[:,1]\n",
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5x-eKu4rW2dQ"
      },
      "source": [
        "df['segment'] = df.prob.apply(lambda x: 'high' if x > 0.5 else('medium' if x >0.3 else 'low'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3CbeZ6miVsq"
      },
      "source": [
        "df.segment.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzmmnfQUYCvq"
      },
      "source": [
        "df = df.loc[:, ['clientid', 'segment']]\n",
        "df.columns = [index_dimension, value_dimension]\n",
        "df.to_csv('dataset.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTAVp-q7icxP"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}